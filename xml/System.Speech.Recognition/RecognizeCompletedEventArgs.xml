<Type Name="RecognizeCompletedEventArgs" FullName="System.Speech.Recognition.RecognizeCompletedEventArgs">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="67c49cb4c1ae63411a75b40985060c682b2e066a" />
    <Meta Name="ms.sourcegitcommit" Value="5a49536d99d2d0b54e4cb7280870903e043272df" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="de-DE" />
    <Meta Name="ms.lasthandoff" Value="07/03/2018" />
    <Meta Name="ms.locfileid" Value="37755927" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class RecognizeCompletedEventArgs : System.ComponentModel.AsyncCompletedEventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit RecognizeCompletedEventArgs extends System.ComponentModel.AsyncCompletedEventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizeCompletedEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizeCompletedEventArgs&#xA;Inherits AsyncCompletedEventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizeCompletedEventArgs : System::ComponentModel::AsyncCompletedEventArgs" />
  <TypeSignature Language="F#" Value="type RecognizeCompletedEventArgs = class&#xA;    inherit AsyncCompletedEventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.ComponentModel.AsyncCompletedEventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>Stellt Daten für das <see langword="RecognizeCompleted" />-Ereignis bereit, das von einem <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />- oder einem <see cref="T:System.Speech.Recognition.SpeechRecognizer" />-Objekt ausgelöst wird.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Eine Instanz von <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> wird erstellt, wenn die <xref:System.Speech.Recognition.SpeechRecognitionEngine> oder <xref:System.Speech.Recognition.SpeechRecognizer> -Objekt löst die `SpeechRecognized` Ereignis nach Abschluss einer `RecognizeAsync` Vorgang. Weitere Informationen zu Speech Recognition-Ereignissen finden Sie unter [mit Speech Recognition Ereignissen](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).  
  
   
  
## Examples  
 Im folgende Beispiel führt die asynchrone Spracherkennung verwendet für eine spracherkennungsgrammatik, mit der <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> -Methode mit der in-Process-Erkennung. Im Beispiel wird <xref:System.Speech.Recognition.Choices> und <xref:System.Speech.Recognition.GrammarBuilder> Objekte spracherkennungsgrammatik zu erstellen, vor dem erstellen ihn in eine <xref:System.Speech.Recognition.Grammar> Objekt. Ein Handler für die <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> Ereignis gibt Informationen zu den Erkennungsvorgang an die Konsole.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
    <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
    <altmember cref="T:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs" />
  </Docs>
  <Members>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft die Position im Audiostream des Eingabegeräts ab, die dem <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />-Ereignis zugeordnet ist.</summary>
        <value>Die Position im Audiostream des Eingabegeräts, der dem <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />-Ereignis zugeordnet ist.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Diese Eigenschaft verweist auf die Position am Anfang des dem erkannten Ausdruck im generierten Audiostream für das Eingabegerät. Im Gegensatz dazu die <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> -Eigenschaft verweist auf die Erkennung der Position in der Audioeingabe. Diese Positionen können unterschiedlich sein. Weitere Informationen finden Sie unter [mit Speech Recognition Ereignissen](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).  
  
   
  
## Examples  
 Im folgende Beispiel führt die asynchrone Spracherkennung verwendet für eine spracherkennungsgrammatik, mit der <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> -Methode mit der in-Process-Erkennung. Im Beispiel wird <xref:System.Speech.Recognition.Choices> und <xref:System.Speech.Recognition.GrammarBuilder> Objekte spracherkennungsgrammatik zu erstellen, vor dem erstellen ihn in eine <xref:System.Speech.Recognition.Grammar> Objekt. Ein Handler für die <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> Ereignis gibt Informationen zu den Erkennungsvorgang an die Konsole.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="BabbleTimeout">
      <MemberSignature Language="C#" Value="public bool BabbleTimeout { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool BabbleTimeout" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property BabbleTimeout As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool BabbleTimeout { bool get(); };" />
      <MemberSignature Language="F#" Value="member this.BabbleTimeout : bool" Usage="System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft einen Wert ab, der angibt, ob ein Geplappertimeout das <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />-Ereignis generiert hat.</summary>
        <value>
          <see langword="true" />, wenn <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> nur Hintergrundgeräusch für länger als in der <see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />-Eigenschaft angegeben erkannt hat; andernfalls <see langword="false." /></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Im folgende Beispiel führt die asynchrone Spracherkennung verwendet für eine spracherkennungsgrammatik, mit der <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> -Methode mit der in-Process-Erkennung. Im Beispiel wird <xref:System.Speech.Recognition.Choices> und <xref:System.Speech.Recognition.GrammarBuilder> Objekte spracherkennungsgrammatik zu erstellen, vor dem erstellen ihn in eine <xref:System.Speech.Recognition.Grammar> Objekt. Ein Handler für die <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> Ereignis gibt Informationen zu den Erkennungsvorgang an die Konsole.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />
      </Docs>
    </Member>
    <Member MemberName="InitialSilenceTimeout">
      <MemberSignature Language="C#" Value="public bool InitialSilenceTimeout { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool InitialSilenceTimeout" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property InitialSilenceTimeout As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool InitialSilenceTimeout { bool get(); };" />
      <MemberSignature Language="F#" Value="member this.InitialSilenceTimeout : bool" Usage="System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft einen Wert ab, der angibt, ob das ursprüngliche Ruhetimeout <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />-Ereignis generiert hat.</summary>
        <value>
          <see langword="true" />, wenn die <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> nur Ruhe für länger als in der <see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />-Eigenschaft angegeben erkannt hat; andernfalls <see langword="false." /></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 Im folgende Beispiel führt die asynchrone Spracherkennung verwendet für eine spracherkennungsgrammatik, mit der <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> -Methode mit der in-Process-Erkennung. Im Beispiel wird <xref:System.Speech.Recognition.Choices> und <xref:System.Speech.Recognition.GrammarBuilder> Objekte spracherkennungsgrammatik zu erstellen, vor dem erstellen ihn in eine <xref:System.Speech.Recognition.Grammar> Objekt. Ein Handler für die <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> Ereignis gibt Informationen zu den Erkennungsvorgang an die Konsole.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />
      </Docs>
    </Member>
    <Member MemberName="InputStreamEnded">
      <MemberSignature Language="C#" Value="public bool InputStreamEnded { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool InputStreamEnded" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property InputStreamEnded As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool InputStreamEnded { bool get(); };" />
      <MemberSignature Language="F#" Value="member this.InputStreamEnded : bool" Usage="System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft einen Wert, der angibt, ob der Eingabedatenstrom beendet worden ist.</summary>
        <value>
          <see langword="true" />, wenn das Erkennungsmodul keine Audioeingabe mehr hat; andernfalls <see langword="false" />.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die Erkennung wird diese Eigenschaft auf `true` Wenn eine Datei enthält den Eingabedatenstrom für die Erkennung und das Ende der Datei erreicht ist. Das Ende des Eingabestreams kann mit einem Vorgang für die erfolgreiche Erkennung übereinstimmen. Weitere Informationen zur Verwendung einer Datei als den Eingabedatenstrom finden Sie unter den <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A> und <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> Methoden.  
  
   
  
## Examples  
 Im folgende Beispiel führt die asynchrone Spracherkennung verwendet für eine spracherkennungsgrammatik, mit der <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> -Methode mit der in-Process-Erkennung. Im Beispiel wird <xref:System.Speech.Recognition.Choices> und <xref:System.Speech.Recognition.GrammarBuilder> Objekte spracherkennungsgrammatik zu erstellen, vor dem erstellen ihn in eine <xref:System.Speech.Recognition.Grammar> Objekt. Ein Handler für die <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> Ereignis gibt Informationen zu den Erkennungsvorgang an die Konsole.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="Result">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult Result { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognitionResult Result" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizeCompletedEventArgs.Result" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Result As RecognitionResult" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognitionResult ^ Result { System::Speech::Recognition::RecognitionResult ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Result : System.Speech.Recognition.RecognitionResult" Usage="System.Speech.Recognition.RecognizeCompletedEventArgs.Result" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Ruft das Erkennungsergebnis ab.</summary>
        <value>Das Erkennungsergebnis, wenn der Erkennungsvorgang erfolgreich war; andernfalls <see langword="null" />.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Die <xref:System.Speech.Recognition.RecognitionResult> Objekt abgeleitet <xref:System.Speech.Recognition.RecognizedPhrase> und vollständige Informationen zu einem Ausdruck zurückgegeben werden, indem ein Erkennungsvorgang enthält.  
  
   
  
## Examples  
 Im folgende Beispiel führt die asynchrone Spracherkennung verwendet für eine spracherkennungsgrammatik, mit der <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> -Methode mit der in-Process-Erkennung. Im Beispiel wird <xref:System.Speech.Recognition.Choices> und <xref:System.Speech.Recognition.GrammarBuilder> Objekte spracherkennungsgrammatik zu erstellen, vor dem erstellen ihn in eine <xref:System.Speech.Recognition.Grammar> Objekt. Ein Handler für die <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> Ereignis gibt Informationen zu den Erkennungsvorgang an die Konsole.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
      </Docs>
    </Member>
  </Members>
</Type>